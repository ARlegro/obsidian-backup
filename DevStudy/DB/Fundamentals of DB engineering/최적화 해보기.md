
### 이전 코드 
아래는 내가 맡은 배치 알림 생성을 위해 필요한 정보들을 가져오는 쿼리이다.
다른 팀원이 작성하였으며, 나는 그냥 이 메서드를 사용하기만 했다.
```JAVA 
  //특정시간 이후 등록된 모든 관심사-기사, 관심사별로 기사수를 가져옴  
  //관심사-유저와 위 테이블 조인  
  //유저-관심사-기사수를 구한다. -> 해당 엔티티마다 notification 전부 만들어야한다.  
  @Query(  
      "SELECT s.interest AS interest, s.user AS user, COUNT(ai) AS articleCount " +  
          "FROM Subscription as s " +  
          "JOIN ArticleInterest ai ON s.interest = ai.interest " +  
          "WHERE ai.createdAt > :afterAt " +  
          "GROUP BY s.interest, s.user"  
  )  
  List<UnreadInterestArticleCount> findNewArticleCountWithUserInterest(  
      @Param("afterAt") Instant afterAt);  
  
}
```

![[Pasted image 20250610130848.png]]

### 기존 코드의 문제
연관관계가 없는 JOIN이 일어났다 (ArticleInterest On Inter)
```SQL
EXPLAIN ANALYZE SELECT
  s.interest_id    AS interest_id,
  s.user_id        AS user_id,
  COUNT(ai.article_id) AS article_count
FROM users_interests AS s
JOIN articles_interests AS ai
  ON s.interest_id = ai.interest_id
WHERE ai.created_at > '2025-06-09T04:24:33Z'   -- :afterAt 파라미터에 해당하는 타임스탬프
GROUP BY
  s.interest_id,
  s.user_id
;
```

이 쿼리를 실행했을 때 20분이 지나도 무한로딩 상태에 빠졌다
![[Pasted image 20250611143226.png]]
아무래도 너무너무 조인이 많고 불필요한게 많아서 그런 것 같다.
`EXPLAIN ANALYZE` 말고 `EXPLAIN`으로 분석하자 

```SQL
QUERY PLAN

GroupAggregate  (cost=70337.53..912383717.37 rows=100346 width=40)
  Group Key: s.interest_id, s.user_id
  ->  Merge Join  (cost=70337.53..608317776.98 rows=40541991591 width=48)
        Merge Cond: (s.interest_id = ai.interest_id)
        ->  Gather Merge  (cost=31630.55..89863.79 rows=500000 width=32)
              Workers Planned: 2
              ->  Sort  (cost=30630.52..31151.36 rows=208333 width=32)
                    Sort Key: s.interest_id, s.user_id
                    ->  Parallel Seq Scan on users_interests s  (cost=0.00..7238.33 rows=208333 width=32)
        ->  Materialize  (cost=38706.98..110086.87 rows=600000 width=32)
              ->  Gather Merge  (cost=38706.98..108586.87 rows=600000 width=32)
                    Workers Planned: 2
                    ->  Sort  (cost=37706.96..38331.96 rows=250000 width=32)
                          Sort Key: ai.interest_id
                          ->  Parallel Seq Scan on articles_interests ai  (cost=0.00..9311.00 rows=250000 width=32)
                                Filter: (created_at > '2025-06-09 04:24:33+00'::timestamp with time zone)
JIT:
  Functions: 14
  Options: Inlining true, Optimization true, Expressions true, Deforming true
```





|방법|쿼리 수|JOIN 수|메모리 사용량|
|---|---|---|---|
|**기존**|1개|3개|높음 (전체 엔티티)|
|**당신 제안**|N+1개|1개|중간|
|**한 방 쿼리**|1개|2개|낮음 (필요 컬럼만)|




일단 
```java
  
  public static NotificationJdbc create(UnreadInterestArticleCount unreadInterestArticleCount) {  
    Instant createdAt = Instant.now();  
    return NotificationJdbc.builder()  
        .id(UUID.randomUUID())  
        .userId(unreadInterestArticleCount.getUser().getId())  
        .resourceId(unreadInterestArticleCount.getInterest().getId())  
        .resourceType(ResourceType.INTEREST)  
        .content(  
            unreadInterestArticleCount.getInterest().getName() + "와/과 관련된 기사가 "                + unreadInterestArticleCount.getArticleCount()  
                + "건 등록되었습니다.")  
        .createdAt(createdAt)  
        .updatedAt(createdAt)  
        .confirmed(false)  
        .build();  
  }  
}
```
알림 생성로직은 다음과 같다.
보면 user관련 컬럼은 user ID만 필요.
즉, user 전체를 테이블에서 꺼내는건 매우 비효율적
userId만 index Only Scan을 사용하는 것을 권장 



```java 
@Service
public class NotificationBatchService {
    
    private final NotificationRepository notificationRepository;
    
    // 방법 1: 한 번의 쿼리로 모든 정보 조회
    public List<NotificationJdbc> createNotificationsFromNewArticles(Instant afterAt) {
        List<Object[]> results = notificationRepository.findNewArticleCountForNotification(afterAt);
        
        return results.stream()
            .map(NotificationQueryResult::from)
            .map(NotificationJdbc::create)
            .toList();
    }
    
    // 방법 2: 2단계로 나누어 처리 (대용량 데이터에 더 효율적일 수 있음)
    public List<NotificationJdbc> createNotificationsFromNewArticlesTwoStep(Instant afterAt) {
        // 1단계: 새 기사가 있는 관심사만 조회
        List<Object[]> interestResults = notificationRepository.findInterestsWithNewArticles(afterAt);
        
        if (interestResults.isEmpty()) {
            return Collections.emptyList();
        }
        
        List<UUID> interestIds = interestResults.stream()
            .map(row -> (UUID) row[0])
            .toList();
            
        // 2단계: 해당 관심사들의 구독자별 기사 수 조회
        List<Object[]> userResults = notificationRepository
            .findUserArticleCountByInterests(interestIds, afterAt);
            
        // 관심사 이름 매핑을 위한 Map 생성
        Map<UUID, String> interestNameMap = interestResults.stream()
            .collect(Collectors.toMap(
                row -> (UUID) row[0],
                row -> (String) row[1]
            ));
            
        return userResults.stream()
            .map(row -> new NotificationQueryResult(
                (UUID) row[0],  // user_id
                (UUID) row[1],  // interest_id
                interestNameMap.get((UUID) row[1]), // interest_name
                ((Number) row[2]).longValue() // article_count
            ))
            .map(NotificationJdbc::create)
            .toList();
    }
}
```


### 개선 방안 1. 한방 쿼리 

```JAVA 
@Query(value = """ 
		SELECT 
				ui.user_id,
				ui.interest_id, 
				i.name as interest_name, 
				COUNT(ai.article_id) as article_count 
		FROM articles_interests ai 
		JOIN users_interests ui ON ai.interest_id = ui.interest_id 
		JOIN interests i ON ui.interest_id = i.id 
		WHERE ai.created_at > :afterAt 
		GROUP BY ui.user_id, ui.interest_id, i.name
		""", nativeQuery = true) 
List<Object[]> findUserNotificationData(@Param("afterAt") Instant afterAt);
```

```SQL
CREATE INDEX idx_articles_interests_created_at ON articles_interests(created_at); CREATE INDEX idx_articles_interests_interest_created ON articles_interests(interest_id, created_at);
```


### 개선 방안 2. 여러방 쿼리 

> 핵심은 Interest이다 .

알림 객체 생성 로직을 다시 돌이켜보자. 
아래는 Srping-Batch에서 JDBC Insert를 위해 알림 객체를 생성하는 로직이다.
```java 
@Builder  
public record NotificationJdbc(  
    UUID id,  
    UUID userId,  
    UUID resourceId,  
    ResourceType resourceType,  
    String content,  
    Instant createdAt,  
    Instant updatedAt,  
    boolean confirmed) {  
  
  public static NotificationJdbc create(UnreadInterestArticleCount unreadInterestArticleCount) {  
    Instant createdAt = Instant.now();  
    return NotificationJdbc.builder()  
        .id(UUID.randomUUID())  
        .userId(unreadInterestArticleCount.getUser().getId())  
        .resourceId(unreadInterestArticleCount.getInterest().getId())  
        .resourceType(ResourceType.INTEREST)  
        .content(  
            unreadInterestArticleCount.getInterest().getName() + "와/과 관련된 기사가 "                + unreadInterestArticleCount.getArticleCount()  
                + "건 등록되었습니다.")  
        .createdAt(createdAt)  
        .updatedAt(createdAt)  
        .confirmed(false)  
        .build();  
  }
```

>[!tip] 정말 필요한게 뭐였을까??
>DB부하를 줄이고 인덱스를 극대화하기 위해서는 정말 필요한 컬럼들만 있으면 된다.
>1. 관련 기사 수 ⭐ 
>	- 여기서 크게 성능을 최적화 할 수 있는 부분이였다.
>	- 이전 : 당연히 관련 기사 수 이니 관련된 Article.count()를 이용하려 했다.
>	- 개선 : articles_interests테이블에서 interestsId에 맞는 article_id의 count만 따로 가져올 수 있다. 이렇게 되면 article 테이블을 조회하지 않아도 된다.
>2. Interest 
>	- 필요 컬럼 : id, name
>	- 필요 없는 컬럼 : keywords, createdAt
>	- 필요 없는 컬럼을 빼고 가져오는게 메모리 적으로도 좋고, 인덱스 활용면에서도 더 좋아 보인다.
>	  
>3. User
>	- 필요 컬럼 : id
>	- 생성된 article가 관련된 Interest를 가지고 있는 user의 id 
>	- 


핵심은 Interest ⭐⭐
- Interest에 맞는 기사 수 
- Interest를 갖고 있는 user Id
- 그리고 그냥 Interest 그 자체 


1. articles_Interests 테이블에서 생성된 기사의 id와 그에 맞는 
2. 1번에서 얻은 id를 가지고 interest의 name 조회 
3. 



## 여러방 쿼리 분석 


### 1. 쿼리 최적화
총 3방의 쿼리가 나갈 것이다. 

```SQL 
SELECT
  ai.interest_id,
  COUNT(*)            AS article_count
FROM articles_interests ai
WHERE ai.created_at > '2025-05-22T05:07:16Z'
GROUP BY ai.interest_id;


QUERY PLAN

Finalize GroupAggregate  (cost=11561.08..11561.84 rows=3 width=24) (actual time=39.124..40.637 rows=3 loops=1)
  Group Key: interest_id
  ->  Gather Merge  (cost=11561.08..11561.78 rows=6 width=24) (actual time=39.119..40.632 rows=9 loops=1)
        Workers Planned: 2
        Workers Launched: 2
        ->  Sort  (cost=10561.05..10561.06 rows=3 width=24) (actual time=37.477..37.477 rows=3 loops=3)
              Sort Key: interest_id
              Sort Method: quicksort  Memory: 25kB
              Worker 0:  Sort Method: quicksort  Memory: 25kB
              Worker 1:  Sort Method: quicksort  Memory: 25kB
              ->  Partial HashAggregate  (cost=10561.00..10561.03 rows=3 width=24) (actual time=37.453..37.454 rows=3 loops=3)
                    Group Key: interest_id
                    Batches: 1  Memory Usage: 24kB
                    Worker 0:  Batches: 1  Memory Usage: 24kB
                    Worker 1:  Batches: 1  Memory Usage: 24kB
                    ->  Parallel Seq Scan on articles_interests ai  (cost=0.00..9311.00 rows=250000 width=16) (actual time=0.024..15.998 rows=200000 loops=3)
                          Filter: (created_at > '2025-06-09 05:07:16+00'::timestamp with time zone)
Planning Time: 0.247 ms
Execution Time: 40.695 ms
```


```SQL 

EXPLAIN ANALYZE SELECT
  i.id,
  i.name
FROM interests i
WHERE i.id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
);


QUERY PLAN

Bitmap Heap Scan on interests i  (cost=4.17..11.28 rows=3 width=134) (actual time=0.027..0.027 rows=3 loops=1)
  Recheck Cond: (id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
  Heap Blocks: exact=1
  ->  Bitmap Index Scan on interests_pkey  (cost=0.00..4.17 rows=3 width=0) (actual time=0.019..0.020 rows=3 loops=1)
        Index Cond: (id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
Planning Time: 0.378 ms
Execution Time: 0.043 ms

```



```SQL 

SELECT
  ui.interest_id,
  ARRAY_AGG(ui.user_id) AS user_ids
FROM users_interests ui
WHERE ui.interest_id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
)
GROUP BY ui.interest_id;

QUERY PLAN

Finalize GroupAggregate  (cost=9443.83..9445.13 rows=5 width=48) (actual time=81.508..85.231 rows=2 loops=1)
  Group Key: interest_id
  ->  Gather Merge  (cost=9443.83..9444.99 rows=10 width=48) (actual time=74.107..75.776 rows=6 loops=1)
        Workers Planned: 2
        Workers Launched: 2
        ->  Sort  (cost=8443.80..8443.82 rows=5 width=48) (actual time=66.848..66.853 rows=2 loops=3)
              Sort Key: interest_id
              Sort Method: quicksort  Memory: 1439kB
              Worker 0:  Sort Method: quicksort  Memory: 1370kB
              Worker 1:  Sort Method: quicksort  Memory: 1367kB
              ->  Partial HashAggregate  (cost=8443.68..8443.75 rows=5 width=48) (actual time=51.528..65.614 rows=2 loops=3)
                    Group Key: interest_id
                    Batches: 1  Memory Usage: 2961kB
                    Worker 0:  Batches: 1  Memory Usage: 2961kB
                    Worker 1:  Batches: 1  Memory Usage: 2385kB
                    ->  Parallel Seq Scan on users_interests ui  (cost=0.00..8019.58 rows=84820 width=32) (actual time=0.024..20.705 rows=66667 loops=3)
                          Filter: (interest_id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
                          Rows Removed by Filter: 100000
Planning Time: 0.617 ms
Execution Time: 85.449 ms
```


아직 인덱스 최적화도 안 했는데 단순히 쿼리만 손댔는데도 이렇게 빠른 속도로 변했다.


### 2. 인덱스 최적화 

흠....
근데 인덱스, 커버링 인덱스 등으로 최적화하는게 과연 맞을까?
서비스 특성상 조회가 많긴 한데 수정, 삽입 작업도 많아서
일단 관련된 기능들을 살펴보자 
1. 기사 
2. 관심사
3. 유저 

- 우선 **기사**는 매시간마다 대량으로 삽입되니까 기사와 관련된 것들을 인덱스로 만들기에는 비용이 많이 들 것 같아서 기사와 관련된 인덱스 ❌ (article, articles_interests ❌)
- 그 다음, **관심사**는 음.... 관심사를 그렇게 자주 수정할 일은 없을 것 같다. 뉴스도 보던 것들만 보는 특성을 가지기에 이거는 해볼만 한 것 같다.
- 그 다음, **유저**는 쿼리에서 user에게 필요한건 id뿐이다. 근데 id는 이미 PRIMARY KEY로 인덱스 등록이 되어있으므로 딱히 쿼리최적화 후 건들 것이 없다. 그래도 users_interests테이블에 user_id관련 필드는 FK이므로 이 부분은 생각해볼만 하다. 인기가 많은 서비스라면 유저가 자주 바뀌겠지만 그렇지 않다고 가정하고 최적화를 위해 해볼만하다 

그럼 이 조건들에 맞아 인덱스를 적용할 수 있는 테이블들은 최종적으로 interests와 users_interests테이블이다.
간단하게 생각해보면 
- users_interests에서는 userId와 interestId부분을 커버링 인덱스로 처리해 볼 수 있다.
- interest도 id, name필드만 필요하므로 이 부분도 가능 ???



