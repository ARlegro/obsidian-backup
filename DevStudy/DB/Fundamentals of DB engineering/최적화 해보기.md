
> Branch 
> - main : 원본 프로젝트
> - optimize : 최적화 도입한 부분만 

## 개선 전략 비교표
5개의 테이블 
총 50M ~ 100M 더미데이터 환경에서 테스트 

| 전략               | 쿼리 수 | JOIN 수 | 메모리 부하 | 속도    |
| ---------------- | ---- | ------ | ------ | ----- |
| **기존**           | 1    | 3      | 높음     | 무한로딩  |
| **쿼리 최적화 후**     | 3    | 0      | 낮음     | 125ms |
| **쿼리 최적화 + 인덱싱** | 3    | 0      | 낮음     |       |
(참고 : 여기서 쿼리 수는 DB와 애플리케이션 간의 쿼리입니다)


이전에 Monew라는 기사 제공 프로젝트를 맡았습니다.
(링크 : [[나중에 넣기]])

그 당시 저는 스프링 배치를 통해 아래와 같은 것들을 구현했습니다.
- 기사 정기적 수집 및 백업(s3 + db) 배치 
- 기사 복구 배치 
- 알림 생성 (after 기사 생성) 배치 
- 알림 삭제 배치 

## 문제 시작 
### 문제 발생 배경

당시 프로젝트 마감과 자격증, 크래프톤 일정과 겹치면서 성능 최적화에는 충분한 시간을 들이지 못했고, 당시에는 RDB에 대한 이해도 부족으로 인해 단순한 조인 및 한방 쿼리 중심으로 코드를 구성된 프로젝트였습니다. 이후 DB 관련 중급 이상의 학습을 통해 이전 프로젝트들을 돌아보면서 코드 전반에 심각한 성능 이슈가 있음을 인지하게 되었습니다.
특히 다음 메서드에서 치명적인 성능 문제가 발생하였다:
```SQL 
@Query("SELECT s.interest AS interest, s.user AS user, COUNT(ai) AS articleCount " +
       "FROM Subscription as s " +
       "JOIN ArticleInterest ai ON s.interest = ai.interest " +
       "WHERE ai.createdAt > :afterAt " +
       "GROUP BY s.interest, s.user")
List<UnreadInterestArticleCount> findNewArticleCountWithUserInterest(@Param("afterAt") Instant afterAt);
```

이 메서드는 배치 알림 생성(특정 시간 이후 등록된 기사에 대한)을 위해 필요한 데이터들을 DB에서 가져오는 메서드입니다.
여러 테이블을 조인해서 한방 쿼리로 만들었던 이 코드를 최적화해보려고 합니다. 
### 문제 분석 
> 아래는 생성하려는 알림의 테이블과 이를 위해 필요한 5개의 테이블의 ERD입니다.
![[Pasted image 20250610130848.png]]
#### 더미 데이터 세팅 
우선 기존 코드의 성능을 테스트하기 위해 총 50M ~ 100M의 데이터를 만들기로 했습니다.
알림 생성에 필요한 5개의 테이블의 Dummy Data를 아래의 숫자만큼 생성하고 테스트를 시도했습니다.
(더미 생성 코드 : resources -> test-seed.sql)
- Users 데이터 : 10M
- Interest 데이터 : 10개 (관심사는 그렇게 많은 데이터 종류가 아니기에 10개 정도만 생성)
- Article 데이터 : 20M
- Users_Interests : 10M ~ 50M (랜덤 시드)
- Articles_Interests : 10M ~ 20M  

> 시드 코드 : `resources -> test-seed.sql`참고 

#### 테스트 시작 in 대용량 데이터 

> Preview : 실제 5개의 테이블에 대해 대용량 Dummy Data를 삽입한 뒤 위 쿼리를 실행한 결과
> - **무한 로딩** 발생 (20분 이상 진행)
> - **EXPLAIN 결과**: 수억 건 이상의 조인 튜플이 발생
> - **주요 원인**:
> 	1. 연관관계가 없는 테이블 간 JOIN 발생
> 	2. 필요 없는 컬럼까지 전체 엔티티 로딩 → Index Only Scan 불가

실제로 이 테이블에서 만든 쿼리를 EXPLAIN ANALYZE으로 테스트해보았습니다.
일단 애플리케이션에서 무한로딩이 걸려서 아래와 같이 따로 SQLECTRON을 사용해서 시도해봤습니다.
```SQL
EXPLAIN ANALYZE SELECT
  s.interest_id    AS interest_id,
  s.user_id        AS user_id,
  COUNT(ai.article_id) AS article_count
FROM users_interests AS s
JOIN articles_interests AS ai
  ON s.interest_id = ai.interest_id
WHERE ai.created_at > '2025-06-09T04:24:33Z'   -- :afterAt 파라미터에 해당하는 타임스탬프
GROUP BY
  s.interest_id,
  s.user_id
;
```

결과 : 20분째 무한로딩 상태
![[Pasted image 20250611143226.png]]
DB에 엄청난 부하가 가는 쿼리인 것 같습니다. 
실제 실행되는 `EXPLAIN ANALYZE` 말고 `EXPLAIN`으로 어떻게 내부적으로 DB가 작동하는지 분석해보겠습니다.
```SQL
QUERY PLAN

GroupAggregate  (cost=70337.53..912383717.37 rows=100346 width=40)
  Group Key: s.interest_id, s.user_id
  ->  Merge Join  (cost=70337.53..608317776.98 rows=40541991591 width=48)
        Merge Cond: (s.interest_id = ai.interest_id)
        ->  Gather Merge  (cost=31630.55..89863.79 rows=500000 width=32)
              Workers Planned: 2
              ->  Sort  (cost=30630.52..31151.36 rows=208333 width=32)
                    Sort Key: s.interest_id, s.user_id
                    ->  Parallel Seq Scan on users_interests s  (cost=0.00..7238.33 rows=208333 width=32)
        ->  Materialize  (cost=38706.98..110086.87 rows=600000 width=32)
              ->  Gather Merge  (cost=38706.98..108586.87 rows=600000 width=32)
                    Workers Planned: 2
                    ->  Sort  (cost=37706.96..38331.96 rows=250000 width=32)
                          Sort Key: ai.interest_id
                          ->  Parallel Seq Scan on articles_interests ai  (cost=0.00..9311.00 rows=250000 width=32)
                                Filter: (created_at > '2025-06-09 04:24:33+00'::timestamp with time zone)
JIT:
  Functions: 14
  Options: Inlining true, Optimization true, Expressions true, Deforming true
```
- **쿼리 구조**:  
    `users_interests`와 `articles_interests`를 `interest_id`로 조인하고, `created_at` 조건을 필터링한 뒤 `interest_id, user_id` 기준으로 그룹화 및 count.
    
- **병목 요인**:  
    `JOIN` 결과가 **40억건 이상**으로 추산되고 있고, 정렬(Sort) + GroupAggregate 처리까지 한꺼번에 이뤄지면서 병목 발생.
	```SQL
	Merge Join  (cost=70337.53..608317776.98 rows=40541991591 width=48)
	```



#### 문제 원인 분석
위에서 언급하고 테스트한 `findNewArticleCountWithUserInterest`메서드는 성능상 아주 큰 문제가 있습니다.
1. **연관관계가 없는 JOIN이 일어났다** (Subscription - ArticleInterest)
	- 연관관계가 없는 테이블끼리 JOIN을 하면 뭐가 문제일까???
2. **필요한 데이터가 아닌 한 테이블의 모든 컬럼을 가져온다**
	- 이후 개선 방안에서 언급할 내용이지만 어떤 테이블에서는단순히 ID만 필요한 경우도 있따.
	- 단순 ID만 테이블에서 조회할 경우 Index Only Scan 으로 굉장히 성능이 좋게 할 수 있는데 전체 데이터를 가져오려하면 이러한 이점을 이용하지 못해 bitmap scan or Seq Scan으로 더 비효율적인 실행계획이 생길 것입니다.

정말 많은 row에 접근해야하기 때문에 꽤 **비싼 쿼리**

## 개선 시도하기 

### 필요한 데이터 분석 
일단 아래는 Notification을 생성하기 위한 static 메서드이다. 
```java
  
  public static NotificationJdbc create(UnreadInterestArticleCount unreadInterestArticleCount) {  
    Instant createdAt = Instant.now();  
    return NotificationJdbc.builder()  
        .id(UUID.randomUUID())  
        .userId(unreadInterestArticleCount.getUser().getId())  
        .resourceId(unreadInterestArticleCount.getInterest().getId())  
        .resourceType(ResourceType.INTEREST)  
        .content(  
            unreadInterestArticleCount.getInterest().getName() + "와/과 관련된 기사가 "                + unreadInterestArticleCount.getArticleCount()  
                + "건 등록되었습니다.")  
        .createdAt(createdAt)  
        .updatedAt(createdAt)  
        .confirmed(false)  
        .build();  
  }  
}
```



## 쿼리 분리 및 최적화로 성능 개선 
> 50M~100M 데이터를 대상 : 20m+ 무한 로딩 ➡ 125ms로 감축

기존에는 테이블을 조인해서 1방 쿼리를 날렸지만, 이번 성능 최적화를 위해 만든 쿼리는 총 3방의 쿼리가 나갈 것입니다.

### 쿼리 최적화 개선안 주요 핵심 
- **조인 최소화** : 데이터량이 많을수록 조인은 병목의 원인이 되므로 꼭 필요한 경우에만 수행
- **선택적 컬럼 조회** : 필요한 컬럼만 조회하여 메모리 사용과 I/O를 절감
- **핵심 데이터 중심 설계**: 쿼리 수 자체를 줄이기 위해 무엇이 정말 필요한지부터 파악

>🔑 핵심은 Interest이다 . 

알림 객체 생성 로직을 다시 되짚어보겠습니다.
아래는 Srping-Batch에서 JDBC Insert를 위해 알림 객체를 생성하는 로직입니다.
```java 
@Builder  
public record NotificationJdbc(  
    ....
  
  public static NotificationJdbc create(UnreadInterestArticleCount unreadInterestArticleCount) {  
    Instant createdAt = Instant.now();  
    return NotificationJdbc.builder()  
        ....
        .userId(unreadInterestArticleCount.getUser().getId())  
        .resourceId(unreadInterestArticleCount.getInterest().getId())  
        ....
        .content(  
            unreadInterestArticleCount.getInterest().getName() + "와/과 관련된 기사가 "                + unreadInterestArticleCount.getArticleCount()  
                + "건 등록되었습니다.")  
        ....
  }
```

>[!tip] 정말 필요한게 뭐였을까??
>DB부하를 줄이고 인덱스를 극대화하기 위해서는 정말 필요한 컬럼들만 있으면 된다.
>1. **관련 기사 수(Article Count) ⭐** 
>	- 여기서 크게 성능을 최적화 할 수 있는 부분이였다.
>	- **기존** : 당연히 관련 기사 수 이니 관련된 Article.count()를 이용하려 했다.
>	- **개선** : **articles_interests테이블에서** interestsId에 맞는 article_id의 count만 따로 가져올 수 있다. 
>	- 즉, 개선을 하면 **article 테이블을 조회하지 않아도 된다.**
>	  
>2. **Interest** 
>	- **필요 컬럼** : id, name
>	- **필요 없는 컬럼** : keywords, createdAt
>	- 꼭 필요한 컬럼만 가져오면 메모리 낭비를 줄이고, 인덱스 효율도 극대화할 수 있다.
>	  
>3. **User**
>	- **필요 컬럼** : id
>	- 알림을 받을 유저는 해당 `Interest`를 구독한 사용자이므로, 이들의 `id`만 있으면 충분하다.

각 엔티티별 필요한 정보 정리 

| 엔티티                | 필요한 컬럼             |
| ------------------ | ------------------ |
| User               | `id`               |
| Interest           | `id`, `name`       |
| Article (Indirect) | 관련된 기사 수 (`count`) |

- 이처럼 Notification을 생성하는 데 필요한 데이터는 매우 단순합니다. 
- 오히려 테이블 간의 연관 관계와 조인 때문에 불필요하게 많은 데이터를 가져오고 있었던 것입니다.
- 만약 JPA나 Spring만 사용했다면, 이런 비효율을 인지하기 어려웠습니다.  
	- 예를 들어, 단순히 `User`의 `id`만 필요한 상황에서도 전체 유저 데이터를 조회
	- 하지만 `id`는 기본적으로 인덱스가 걸려 있으며, **Index Only Scan**으로 매우 빠르게 조회가 가능


>결국, 모든 핵심은 `Interest`를 중심으로 시작된다.  
>이를 기준으로 전체 구조를 재설계하고, 필요한 데이터만 쿼리하도록 최적화하면 성능은 확연히 향상될 수 있다고 생각합니다.

### 개선 후 전체 흐름 
이번 작업의 핵심은 **불필요한 조인을 제거하고**, **정말 필요한 컬럼만 조회하며**, **데이터량 자체를 줄여 성능을 개선**하는 데 있습니다.  
아래는 최적화된 3개의 분리 쿼리이며, 이후에 각 쿼리의 실행 계획과 성능을 분석합니다.

**✅쿼리 사용 메서드** 
```JAVA 
// 쿼리 1. 20일 안에 생성된 Interest(관심사)에 대한 기사 수 
Map<UUID, Long> articleCountByInterestId = findInterestArticleCount(afterAt);
// 쿼리 2. Interest객체에서 name 필드 가져오기 By InterestId  
Map<UUID, String> interestNameByIds = findInterestNameByIds(articleCountByInterestId.keySet());
// 쿼리 3. 생성된 기사에 맞는 Interest를 가진 User의 id 필드 가져오기 By InterestId  
Map<UUID, List<UUID>> subscribersByInterestId = findSubscriberByIds(articleCountByInterestId.keySet());
```
		
**✅DB에 전달되는 전체 쿼리** 
```SQL 
SELECT
  ai.interest_id,
  COUNT(*)            AS article_count
FROM articles_interests ai
WHERE ai.created_at > '2025-05-22T05:07:16Z'
GROUP BY ai.interest_id;

-- 위의 쿼리에서 가져온 InterestId 기준으로 IN절 수동 삽입 
SELECT
  i.id,
  i.name
FROM interests i
WHERE i.id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
);

SELECT
  ui.interest_id,
  ARRAY_AGG(ui.user_id) AS user_ids
FROM users_interests ui
WHERE ui.interest_id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
)
GROUP BY ui.interest_id;
```

각 쿼리별 실행계획을 보겠습니다.
#### 쿼리 1. 관심사 별 기사 수 조회
```SQL 
SELECT
  ai.interest_id,
  COUNT(*)            AS article_count
FROM articles_interests ai
WHERE ai.created_at > '2025-05-22T05:07:16Z'
GROUP BY ai.interest_id;
```

**✅실행계획** 
```SQL
QUERY PLAN

Finalize GroupAggregate 
  Group Key: interest_id
  ->  Gather Merge  
        Workers Planned: 2
        Workers Launched: 2
        ->  Sort  
              Sort Key: interest_id
              Sort Method: quicksort  Memory: 25kB
              Worker 0:  Sort Method: quicksort  Memory: 25kB
              Worker 1:  Sort Method: quicksort  Memory: 25kB
              ->  Partial HashAggregate  
                    Group Key: interest_id
                    Batches: 1  Memory Usage: 24kB
                    Worker 0:  Batches: 1  Memory Usage: 24kB
                    Worker 1:  Batches: 1  Memory Usage: 24kB
                    ->  Parallel Seq Scan on articles_interests ai  
                          Filter: (created_at > ....

Planning Time: 0.247 ms
Execution Time: 40.695 ms
```
>실행 시간 : 40.7 ms 

| 항목       | 기존 구조 (비효율)               | 개선 후 구조 (최적)            |
| -------- | ------------------------- | ----------------------- |
| 대상 Row 수 | 20M x 10M~50M (`JOIN` 기반) | 20M x 10 (관심사 수)        |
| 성능 영향    | 조인으로 인해 수억 개 튜플 생성        | 단순 필터 + Group By로 대폭 감소 |
- 가장 큰 성능 상승 원인은 "**데이터량 감소**"입니다. 
- **핵심 개선 요인**: 조인을 제거하고 필터 후 Group By만 수행 → I/O, 정렬, 집계 부하가 크게 감소

#### 쿼리 2. 관심사 정보 조회 - 1번에서 얻은 interestId 활용
```SQL 

EXPLAIN ANALYZE SELECT
  i.id,
  i.name
FROM interests i
WHERE i.id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
);
```

**✅실행 계획** 
```SQL
QUERY PLAN

Bitmap Heap Scan on interests i  ...
  Recheck Cond: (id = ...::uuid[]))
  ->  Bitmap Index Scan on interests_pkey  ...
        Index Cond: (id = ANY ...
        
Planning Time: 0.378 ms
Execution Time: 0.043 ms
```
- **기본 키 인덱스**를 활용하고 조회이고 3개의 데이터만 가져오기에 **속도가 매우 빠름**
- 커버링 인덱스를 추가하는 방안도 고려했으나, 이 정도 쿼리에서는 **성능 개선 여지가 거의 없음**
	- 기존 커버링 인덱스 계획 
		```SQL
	  -- 고려했던 인덱스 (현재 필요 X)
		CREATE INDEX ON interests(id) INCLUDE (name)
		```


#### 쿼리 3. 해당 관심사 기사 구독자 조회 
```SQL 
SELECT
  ui.interest_id,
  ARRAY_AGG(ui.user_id) AS user_ids
FROM users_interests ui
WHERE ui.interest_id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
)
GROUP BY ui.interest_id;
```

**✅실행 계획** 
```SQL 
QUERY PLAN

Finalize GroupAggregate ....
  Group Key: interest_id
  ->  Gather Merge  ....
        Workers Planned: 2
        Workers Launched: 2
        ->  Sort  ...
              Sort Key: interest_id
              Sort Method: quicksort  Memory: 1439kB
              Worker 0:  Sort Method: quicksort  Memory: 1370kB
              Worker 1:  Sort Method: quicksort  Memory: 1367kB
              ->  Partial HashAggregate  ....
                    Group Key: interest_id
                    Batches: 1  Memory Usage: 2961kB
                    Worker 0:  Batches: 1  Memory Usage: 2961kB
                    Worker 1:  Batches: 1  Memory Usage: 2385kB
                    ->  Parallel Seq Scan on users_interests ui  ... 
                          Filter: (interest_id = ANY ...::uuid[]))
                          Rows Removed by Filter: 100000
                          
Planning Time: 0.617 ms
Execution Time: 85.449 ms
```
- 실행시간 : 85ms

| 항목       | 기존 구조 (비효율)               | 개선 후 구조 (최적)            |
| -------- | ------------------------- | ----------------------- |
| 대상 Row 수 | 20M x 10M~50M (`JOIN` 포함) | 10M x 10 (관심사 수 기준 필터링) |

- 최대 Row 수는 당연히 한방 쿼리랑 비교할 수 없을 정도로 차이가 심하고, 이로 인해 실행시간 차이가 발생했습니다.
- 이 부분은 인덱스 최적화 부분에서 더 분석할 것이다.

#### 성능 비교 및 쿼리 1 ~ 3 종합 분석 

성능 비교

|        | 기존         | 개선 후       |
| ------ | ---------- | ---------- |
| 실행 시간  | 무한로딩(20m+) | 약 125ms    |
| 조인 수   | 3          | 0          |
| 메모리 사용 | 전체 테이블 로딩  | 필요한 컬럼만 선택 |
| 쿼리 수   | 1          | 3          |

아직 인덱스 최적화도 안 했는데 단순히 쿼리만 손댐으로써 이렇게 빠른 속도로 변했습니다.
이전에는 조인 기반의 거대한 튜플 집계로 인해 수십억 단위 데이터 처리가 필요했으나, 현재는 **필요한 정보만 선별적 쿼리**로 분리하여 처리함으로써 전체 프로세스를 **수 밀리초 단위로 단축**하는 데 성공했습니다.

이를 통해 알 수 있는 점은 
1. 한방 쿼리는 DB에 부하를 심하게 준다. 
2. **쿼리 튜닝 및 흐름 재구성** 만으로도 인덱스‑튜닝 이상의 효과가 가능하다.


## 인덱스 최적화로 추가 성능 개선

참고 : [[Key vs Non-Key column Index]]

### 데이터 특성 기반 고려사항

인덱스, 커버링 인덱스 등으로 최적화를 하기 전에 과연 이게 정말 필요한가? 에 대해 생각해봐야합니다.
서비스 특성상 조회가 많긴 한데 기사같은 경우는 삽입 작업도 많기 때문입니다.
따라서, 여러 생각을 통해 아래와 같이 테이블별 인덱스를 고려해볼 수 있는 부분에 대해서 정리해봤습니다.

| 테이블                | 인덱스 최적화 여부   | 이유                          |
| ------------------ | ------------ | --------------------------- |
| articles           | ❌            | 매시간 대량 삽입, 인덱스 부하 큼         |
| articles_interests | ❌            | 기사량 많아 부담 큼                 |
| interests          | ✅            | 자주 수정되지 않음, 조회 빈도 높음        |
| users              | 기본 PK(id) 존재 | 별도 인덱스 필요 없음                |
| users_interests    | ✅            | interest_id, user_id 자주 사용됨 |

위의 표를 참고로 인덱스를 고려해볼 사항은 다음과 같습니다.
1. Interests테이블에서 id, name을 커버링 인덱스 사용
	- 가능은 하지만 이미 쿼리 최적화만으로  0.043ms이라는 매우 빠른 성능을 가지고 있는 상태에서 굳이? 필요할까에 대해서 의문을 가졌습니다.
	- Intrest가 정말정말 많아지지 않는 이상 높은 선택도를 가진 SQL문이기에 커버링 인덱스를 사용하지 않기로 결정했습니다.
	  
2. users_interests
	- 각 관심사별 userid를 조회하는 쿼리가 있었습니다.
	- 만약 interestId를 Key값으로 userId를 non-key값으로 하는 커버링 인덱스를 사용한다면 기존 85ms의 성능보다 좀 더 빠르지 않을까 생각했습니다.

> 따라서, 2번 users_interests 의 인덱스 최적화를 시도해보도록 하겠습니다.


### 인덱스 적용

```
-- users_interests: 커버링 인덱스
CREATE INDEX ON users_interests(interest_id) INCLUDE (user_Id)
```
- UserId는 SELECT 절에만 쓰이기 때문에 user_id를 non-key 값으로 사용 
- [[Covering Index VS Composite Index]]

실행 시간 분석 
```SQL 
QUERY PLAN

Finalize GroupAggregate  (cost=1000.45..7759.79 rows=5 width=48) (actual time=49.734..53.913 rows=2 loops=1)
  Group Key: interest_id
  ->  Gather Merge  (cost=1000.45..7759.65 rows=10 width=48) (actual time=28.495..45.324 rows=6 loops=1)
        Workers Planned: 2
        Workers Launched: 2
        ->  Partial GroupAggregate  (cost=0.42..6758.47 rows=5 width=48) (actual time=21.036..34.917 rows=2 loops=3)
              Group Key: interest_id
              ->  Parallel Index Only Scan using users_interests_interest_id_user_id_idx on users_interests ui  (cost=0.42..6344.90 rows=82701 width=32) (actual time=0.028..7.157 rows=66667 loops=3)
                    Index Cond: (interest_id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
                    Heap Fetches: 0
                    
Planning Time: 0.065 ms
Execution Time: 55.089 ms
```
- 큰 차이는 없었다.
- 실행 계획을 보면 우선 Index-Only-Scan으로 작동하고 있는 것 같다.

### Index-Only-Scan임에도 생각보다 성능최적화가 안되는 이유 분석 

1. **선택도가 낮다**
	- 우선 조회되는 ROW는 interest_id는 10개 미만 각 interestId에 매칭된 `List<userID>`는 최대 10M이다.
	- InterstId는 전체로 봤을 때 10개밖에 되지 않기에 어떻게든 낮은 선택도를 가지고 있다.
	- 따라서 이러한 조건에서는 Seq Scan과의 I/O 차이가 크지 않다
	  
2. **인덱스 페이지 밀도**
	- `(interest_id) INCLUDE (user_id)` 는 key + non-key라 인덱스 페이지가 두껍다. 같은 row 세트를 읽으려면 **더 많은 인덱스 페이지**를 들춰야 하므로 순차 I/O 대비 이득이 희석된다.

### 개선안 생각 

아직 DB에서 파티셔닝, 샤딩, 물질화 이런거를 배우지 않아서 극한으로 최적화하지는 못하는 수준입니다.
하지만 서비스 특성을 고려했을 때, 이 부분에서 더 이상 빠른 최적화가 필요할까? 라는 생각이 들었습니다.
우선 쿼리 최적화로 50M ~ 100M에 달하는 대용량 데이터를 총합 125ms로 쿼리를 완성한 상태입니다.
현재 쿼리 테스트를 하는 부분은 기사가 매 시간 배치작으로 생성되면 그 기사의 관심사를 구독중인 user들에게 알림을 보내는 부분입니다.
과연 알림이 10초 늦게 간다고 사용자 경험이 줄어들까?라고 생각을 했을 때. 아니요! 라고 생각이 들었습니다. 이런 서비스에서 중요한 것은 알림 자체가 누락되지 않고 울리는 것이라고 생각했습니다.
따라서 대용량 데이터를 안정적으로 다룰 수 있는 부분만 개선하면 된다고 생각하여 인덱스는 삭제 후 쿼리최적화만 적용하기로 결정했습니다.

## 쿼리 + 인덱싱 개선을 하며 얻은 교훈

이번 리팩토링을 통해 다음과 같은 효과를 얻을 수 있었습니다:
- **쿼리 튜닝 및 흐름 재구성** 만으로도 인덱스‑튜닝 이상의 효과가 가능하다.
	- 무한 로딩 → 125ms 수준으로 감소
- **인덱스 설계 이해**
	- 인덱스를 이전에 공부했었지만 실전 프로젝트에 도입하면서 헷갈리는 점들이 있었습니다.
	- 복합인덱스와 커버링 인덱스의 차이가 뭐지? 라는 의문이 들어 깊게 파고 들었고 어떤 상황에 어떤 인덱스를 써야하는지 체화 시킬 수 있었습니다. 
	- 또한, Index Only Scan이 항상 좋은거는 아니라는 것을 알았지만 한 인덱스에 매칭되는 INCLUDE 컬럼이 몇십만일 때라는 특이한 케이스에서는 실제로 어떤가에 대해서 체화시키는 경험을 했습니다.
- **DB 중심 사고 전환**: JPA 중심 사고에서 탈피하여 RDB 최적화 관점 습득
	- 이전에 DB에 대해서 SQL문 정도만 알고 있을 시절에 코드를 짤 때 있던 안 좋은 습관들을 DB관점에서 보며 해결할 수 있게되었습니다.





