
> Branch 
> - main : 원본 프로젝트
> - optimize : 최적화 도입한 부분만 


이전에 Monew라는 기사 제공 프로젝트를 맡았습니다.
(링크 : [[나중에 넣기]])

그 당시 저는 스프링 배치를 통해 아래와 같은 것들을 구현했습니다.
- 기사 정기적 수집 및 백업(s3 + db) 배치 
- 기사 복구 배치 
- 알림 생성 (after 기사 생성) 배치 
- 알림 삭제 배치 

당시 프로젝트 마감일과 정처기 시험, 크래프톤 정글 자소서 및 실기 시험이 겹쳐서 좀 더 프로젝트에 집중을 하지 못했었습니다.
이후, ACID, 동시성, 인덱스 등 중(하)급수준의 DB공부를 하다가 Monew 프로젝트에서 좀 더 개선할 만한 부분이 무조건 있을거라는 생각하에 다시 되돌아보게 되었습니다.

DB에 대한 이해도가 많이 없었을 시절에는 단순히 "DB는 그냥 저장하는 곳이고 접근 횟수를 줄일수록 좋다"라고만 인지하고 있었습니다. 하지만 DB에 대해 깊이 들어갈수록 이전에 보았던 스프링 코드의 굉장히 큰 문제들이 대거 눈에 보이기 시작했습니다 (타인의 코드뿐만 아니라 제 코드도 포함입니다)

이번에는 그 중 하나인 여러 테이블을 조인해서 한방 쿼리로 만들었던 팀원의 코드를 최적화해보려고 합니다. 
### 기존 코드 
아래의 코드는 배치 알림 생성(특정 시간 이후 등록된 기사에 대한)을 위해 필요한 데이터들을 DB에서 가져오는 메서드입니다. 
```JAVA 
  //특정시간 이후 등록된 모든 관심사-기사, 관심사별로 기사수를 가져옴  
  //관심사-유저와 위 테이블 조인  
  //유저-관심사-기사수를 구한다. -> 해당 엔티티마다 notification 전부 만들어야한다.  
  @Query(  
      "SELECT s.interest AS interest, s.user AS user, COUNT(ai) AS articleCount " +  
          "FROM Subscription as s " +  
          "JOIN ArticleInterest ai ON s.interest = ai.interest " +  
          "WHERE ai.createdAt > :afterAt " +  
          "GROUP BY s.interest, s.user"  
  )  
  List<UnreadInterestArticleCount> findNewArticleCountWithUserInterest(  
      @Param("afterAt") Instant afterAt);  
  
}
```
> 아래는 생성하려는 알림의 테이블과 이를 위해 필요한 5개의 테이블의 ERD입니다.
![[Pasted image 20250610130848.png]]

### 기존 코드 테스트 및 문제점 

#### 세팅 
우선 기존 코드의 성능을 테스트해보기로 했습니다.
대용량의 데이터를 테스트하기 위해 알림 생성에 필요한 5개의 테이블의 Dummy Data를 아래의 숫자만큼 생성하고 테스트를 시도했습니다.
(더미 생성 코드 : resources -> test-seed.sql)
- Users 데이터 : 10M
- Interest 데이터 : 10개 (관심사는 그렇게 많은 데이터 종류가 아니기에 10개 정도만 생성)
- Article 데이터 : 20M
- Users_Interests : 10M ~ 50M 
- Articles_Interests : 10M ~ 20M  

왜 정확한 Data개수가 아니라 범위 데이터인지는 아래의 코드로 더미 데이터를 만들었기 때문입니다.
```SQL 
INSERT INTO users_interests (user_id, interest_id, created_at)  
SELECT DISTINCT  
    u.id,  
    i.id,  
    i.created_at  
FROM users AS u  
CROSS JOIN LATERAL (  
    SELECT *  
    FROM interests  
    ORDER BY random()  
    LIMIT floor(random() * 5 + 1)::int  
) AS i  
ON CONFLICT (user_id, interest_id) DO NOTHING;  
  
INSERT INTO articles_interests(article_id, interest_id)  
SELECT  
    a.id,  
    i.id  
FROM articles AS a  
CROSS JOIN LATERAL (  
    SELECT *  
    FROM interests  
    ORDER BY random()  
    LIMIT Floor(random() * 3 + 1)::int  
) AS i  
ON CONFLICT (article_id, interest_id) DO NOTHING;
```


#### 테스트 시작 in 대용량 데이터 
실제로 이 테이블에서 만든 쿼리를 EXPLAIN ANALYZE으로 테스트해보았습니다.
일단 애플리케이션에서도 무한로딩이 걸려서 아래와 같이 따로 SQL Client를 사용해서 시도해봤습니다.
```SQL
EXPLAIN ANALYZE SELECT
  s.interest_id    AS interest_id,
  s.user_id        AS user_id,
  COUNT(ai.article_id) AS article_count
FROM users_interests AS s
JOIN articles_interests AS ai
  ON s.interest_id = ai.interest_id
WHERE ai.created_at > '2025-06-09T04:24:33Z'   -- :afterAt 파라미터에 해당하는 타임스탬프
GROUP BY
  s.interest_id,
  s.user_id
;
```

결과 : 이 쿼리를 실행했을 때 20분이 지나도 무한로딩 상태에 빠졌다
![[Pasted image 20250611143226.png]]
DB에 엄청난 부하가 가는 쿼리인 것 같습니다. 
`EXPLAIN ANALYZE` 말고 `EXPLAIN`으로 분석하자 

```SQL
QUERY PLAN

GroupAggregate  (cost=70337.53..912383717.37 rows=100346 width=40)
  Group Key: s.interest_id, s.user_id
  ->  Merge Join  (cost=70337.53..608317776.98 rows=40541991591 width=48)
        Merge Cond: (s.interest_id = ai.interest_id)
        ->  Gather Merge  (cost=31630.55..89863.79 rows=500000 width=32)
              Workers Planned: 2
              ->  Sort  (cost=30630.52..31151.36 rows=208333 width=32)
                    Sort Key: s.interest_id, s.user_id
                    ->  Parallel Seq Scan on users_interests s  (cost=0.00..7238.33 rows=208333 width=32)
        ->  Materialize  (cost=38706.98..110086.87 rows=600000 width=32)
              ->  Gather Merge  (cost=38706.98..108586.87 rows=600000 width=32)
                    Workers Planned: 2
                    ->  Sort  (cost=37706.96..38331.96 rows=250000 width=32)
                          Sort Key: ai.interest_id
                          ->  Parallel Seq Scan on articles_interests ai  (cost=0.00..9311.00 rows=250000 width=32)
                                Filter: (created_at > '2025-06-09 04:24:33+00'::timestamp with time zone)
JIT:
  Functions: 14
  Options: Inlining true, Optimization true, Expressions true, Deforming true
```
DB옵티마이저가 계획한 기존 코드의 계획 Flow를 먼저 분석해보겠습니다.
1. Parallel Seq Scan
	- 전체 테이블을 병렬로 순차 스캔을 했습니다.
	- Parallel 기능은 PostgreSQL에서 제공하는 성능 최적화 기능입니다(MySQL은 공부 안 해서 잘 모르겠습니다)
	  
2. Sort 
	- 앞서 1번에서 병렬로 데이터를 가져온다고 하는데 각 Worker들은 데이터를 가져오고 각자 정렬까지 합니다. 왜냐면 이후 3번에서 병합정렬을 하기 위해서는 정렬된 상태로 전달해야 하기 때문입니다.
3. Gather Merger
	- worker들이 가져온 데이터들을 병합정렬합니다.
4. Materialize
5. dsfa
6. asdf

와 너무 많다 이거 분석해줘 gpt 


#### 문제점 분석
위에서 언급하고 테스트한 `findNewArticleCountWithUserInterest`메서드는 성능상 아주 큰 문제가 있습니다.
1. **연관관계가 없는 JOIN이 일어났다** (Subscription - ArticleInterest)
	- 연관관계가 없는 테이블끼리 JOIN을 하면 뭐가 문제일까???
2. **필요한 데이터가 아닌 한 테이블의 모든 컬럼을 가져온다**
	- 이후 개선 방안에서 언급할 내용이지만 어떤 테이블에서는단순히 ID만 필요한 경우도 있따.
	- 단순 ID만 테이블에서 조회할 경우 Index Only Scan 으로 굉장히 성능이 좋게 할 수 있는데 전체 데이터를 가져오려하면 이러한 이점을 이용하지 못해 bitmap scan or Seq Scan으로 더 비효율적인 실행계획이 생길 것입니다.


## 개선 시도하기 

### 필요한 데이터 분석 

일단 아래는 Notification을 생성하기 위한 static 메서드이다. 
```java
  
  public static NotificationJdbc create(UnreadInterestArticleCount unreadInterestArticleCount) {  
    Instant createdAt = Instant.now();  
    return NotificationJdbc.builder()  
        .id(UUID.randomUUID())  
        .userId(unreadInterestArticleCount.getUser().getId())  
        .resourceId(unreadInterestArticleCount.getInterest().getId())  
        .resourceType(ResourceType.INTEREST)  
        .content(  
            unreadInterestArticleCount.getInterest().getName() + "와/과 관련된 기사가 "                + unreadInterestArticleCount.getArticleCount()  
                + "건 등록되었습니다.")  
        .createdAt(createdAt)  
        .updatedAt(createdAt)  
        .confirmed(false)  
        .build();  
  }  
}
```
각 엔티티별 필요한 정보만 일단 파악해보자
- User : id 
- Interest : id, name 
- 생성된 Article 수 

이렇게 보면 Notification을 생성하는데 필요한 DB의 데이터는 정말 별로 없습니다.
단지 테이블이 여러개 엮여있는게 많기에 너무 많은 데이터를 가져오는 거였습니다.
이는, 단순 JPA+Spring만 사용했다면 기존 코드가 성능적으로 얼마나 비효율적인지 알 수 없을 것이고 DB가 어떻게 성능최적화가 이뤄지는지를 알아야 
예를 들어, User테이블을 조회할 때 id가 필요한데 id는 PRIMARY KEY이고 이는 자동으로 인덱스로 등록이 되어 id만 조회 시  index Only Scan으로 최적화가 가능하다 라는 것을 몰랐다면 저도 이전처럼 User데이터 전체를 조회하는 쿼리르 짰을 것입니다.

### 개선 전체 흐름 파악 
개선메서드를 구체적으로 언급하기 전에 Notification 생성을 위해 각 개선 메서드가 서비스 레이어에서 어떻게 상호작용하는지 아래의 코드를 통해 간단해보자 (지금 당장 이해하지 못해도 상관 ❌)
```java 
@Service
public class NotificationBatchService {
    
    private final NotificationRepository notificationRepository;
    
    // 방법 1: 한 번의 쿼리로 모든 정보 조회
  
		public List<NotificationJdbc2> create() {  
		  // 20일 안에 생성된 기사에 대한 알림 생성을 위해   
		Instant targetAt = Instant.now().minus(Duration.ofDays(20));  
		    
		  // 쿼리 1. 20일 안에 생성된 Interest(관심사)에 대한 기사 수   
		Map<UUID, Long> articleCountByInterestId = notificationRepository.findInterestArticleCount(  
		      targetAt);  
		  
		  if (articleCountByInterestId.isEmpty()) {  
		    throw new RuntimeException("articleCountByInterestId is empty");  
		  }  
		  
		  Set<UUID> interestIds = articleCountByInterestId.keySet();  
		  
		  // 쿼리 2. Interest객체에서 name 필드 가져오기 By InterestId  Map<UUID, String> interestNameByIds = notificationRepository.findInterestNameByIds(  
		      interestIds);  
		  
		  // 쿼리 3. 생성된 기사에 맞는 Interest를 가진 User의 id 필드 가져오기 By InterestId  Map<UUID, List<UUID>> subscribersByInterestId = notificationRepository.findSubscriberByIds(interestIds);  
		    
		  // 알림 생성   
		List<NotificationJdbc2> notificationList = new ArrayList<>();  
		  for (UUID interestId : interestIds) {  
		    Long articleCount = articleCountByInterestId.get(interestId);  
		  
		    if (articleCount == null) {  
		      continue;  
		    }  
		  
		    String interestName = interestNameByIds.get(interestId);  
		  
		    if (interestName == null) {  
		      continue;  
		    }  
		  
		    List<UUID> subscribers = subscribersByInterestId.get(interestId);  
		  
		    if (subscribers == null) {  
		      continue;  
		    }  
		  
		    for (UUID subscriber : subscribers) {  
		      NotificationJdbc2 notificationJdbc2 = NotificationJdbc2.create(subscriber, interestId,  
		          interestName, articleCount);  
		      notificationList.add(notificationJdbc2);  
		    }  
		  }  
		  return notificationList;
```

### 개선 아이디어 

> 핵심은 Interest이다 .

알림 객체 생성 로직을 다시 돌이켜보자. 
아래는 Srping-Batch에서 JDBC Insert를 위해 알림 객체를 생성하는 로직이다.
```java 
@Builder  
public record NotificationJdbc(  
    UUID id,  
    UUID userId,  
    UUID resourceId,  
    ResourceType resourceType,  
    String content,  
    Instant createdAt,  
    Instant updatedAt,  
    boolean confirmed) {  
  
  public static NotificationJdbc create(UnreadInterestArticleCount unreadInterestArticleCount) {  
    Instant createdAt = Instant.now();  
    return NotificationJdbc.builder()  
        .id(UUID.randomUUID())  
        .userId(unreadInterestArticleCount.getUser().getId())  
        .resourceId(unreadInterestArticleCount.getInterest().getId())  
        .resourceType(ResourceType.INTEREST)  
        .content(  
            unreadInterestArticleCount.getInterest().getName() + "와/과 관련된 기사가 "                + unreadInterestArticleCount.getArticleCount()  
                + "건 등록되었습니다.")  
        .createdAt(createdAt)  
        .updatedAt(createdAt)  
        .confirmed(false)  
        .build();  
  }
```

>[!tip] 정말 필요한게 뭐였을까??
>DB부하를 줄이고 인덱스를 극대화하기 위해서는 정말 필요한 컬럼들만 있으면 된다.
>1. 관련 기사 수 ⭐ 
>	- 여기서 크게 성능을 최적화 할 수 있는 부분이였다.
>	- 이전 : 당연히 관련 기사 수 이니 관련된 Article.count()를 이용하려 했다.
>	- 개선 : articles_interests테이블에서 interestsId에 맞는 article_id의 count만 따로 가져올 수 있다. 이렇게 되면 article 테이블을 조회하지 않아도 된다.
>2. Interest 
>	- 필요 컬럼 : id, name
>	- 필요 없는 컬럼 : keywords, createdAt
>	- 필요 없는 컬럼을 빼고 가져오는게 메모리 적으로도 좋고, 인덱스 활용면에서도 더 좋아 보인다.
>	  
>3. User
>	- 필요 컬럼 : id
>	- 생성된 article가 관련된 Interest를 가지고 있는 user의 id 

위의 정리와 테이블을 돌이켜보면 핵심은 Interest이다.⭐⭐
- Interest에 맞는 기사 수 
- Interest를 갖고 있는 user Id
- 그리고 그냥 Interest 그 자체 (id, name)


이러한 점을 생각하고 개선을 시도해 보았다.

## 개선 구체화 


### 쿼리 최적화로 성능 개선 
> 결론부터 말하자면, 50M~100M 데이터를 대상으로 
> 20분 넘게 무한 로딩되던 쿼리 ➡ 125ms로 감축


기존에는 테이블을 조인해서 1방 쿼리를 날렸지만, 이번 성능 최적화를 위해 만든 쿼리는 총 3방의 쿼리가 나갈 것입니다.

> 개선의 핵심 : 필요한 데이터만, Join은 가급적 피하기(Cuz 대량의 데이터)

> 3개의 쿼리와 각 쿼리가 갖고 있는 Query Plan을 볼 것입니다.
#### 쿼리 1. 기사 수 집계 + 그에 맞는 interestId
```SQL 
SELECT
  ai.interest_id,
  COUNT(*)            AS article_count
FROM articles_interests ai
WHERE ai.created_at > '2025-05-22T05:07:16Z'
GROUP BY ai.interest_id;


QUERY PLAN

Finalize GroupAggregate  (cost=11561.08..11561.84 rows=3 width=24) (actual time=39.124..40.637 rows=3 loops=1)
  Group Key: interest_id
  ->  Gather Merge  (cost=11561.08..11561.78 rows=6 width=24) (actual time=39.119..40.632 rows=9 loops=1)
        Workers Planned: 2
        Workers Launched: 2
        ->  Sort  (cost=10561.05..10561.06 rows=3 width=24) (actual time=37.477..37.477 rows=3 loops=3)
              Sort Key: interest_id
              Sort Method: quicksort  Memory: 25kB
              Worker 0:  Sort Method: quicksort  Memory: 25kB
              Worker 1:  Sort Method: quicksort  Memory: 25kB
              ->  Partial HashAggregate  (cost=10561.00..10561.03 rows=3 width=24) (actual time=37.453..37.454 rows=3 loops=3)
                    Group Key: interest_id
                    Batches: 1  Memory Usage: 24kB
                    Worker 0:  Batches: 1  Memory Usage: 24kB
                    Worker 1:  Batches: 1  Memory Usage: 24kB
                    ->  Parallel Seq Scan on articles_interests ai  (cost=0.00..9311.00 rows=250000 width=16) (actual time=0.024..15.998 rows=200000 loops=3)
                          Filter: (created_at > '2025-06-09 05:07:16+00'::timestamp with time zone)
Planning Time: 0.247 ms
Execution Time: 40.695 ms
```
- 실행 시간 : 40.7 ms 
- 
#### 쿼리 2. 관심사 정보 조회 - 1번에서 얻은 interestId 활용용
```SQL 

EXPLAIN ANALYZE SELECT
  i.id,
  i.name
FROM interests i
WHERE i.id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
);


QUERY PLAN

Bitmap Heap Scan on interests i  (cost=4.17..11.28 rows=3 width=134) (actual time=0.027..0.027 rows=3 loops=1)
  Recheck Cond: (id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
  Heap Blocks: exact=1
  ->  Bitmap Index Scan on interests_pkey  (cost=0.00..4.17 rows=3 width=0) (actual time=0.019..0.020 rows=3 loops=1)
        Index Cond: (id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
Planning Time: 0.378 ms
Execution Time: 0.043 ms

```


```SQL 

SELECT
  ui.interest_id,
  ARRAY_AGG(ui.user_id) AS user_ids
FROM users_interests ui
WHERE ui.interest_id IN (
  '01f2c804-ea3e-4a36-964d-173b0e7490bf',
  '4e3363f5-673a-4375-b1a4-ff887f63e9fe',
  'c4cb41f8-2cc2-412f-8298-247518a975c3'
)
GROUP BY ui.interest_id;

QUERY PLAN

Finalize GroupAggregate  (cost=9443.83..9445.13 rows=5 width=48) (actual time=81.508..85.231 rows=2 loops=1)
  Group Key: interest_id
  ->  Gather Merge  (cost=9443.83..9444.99 rows=10 width=48) (actual time=74.107..75.776 rows=6 loops=1)
        Workers Planned: 2
        Workers Launched: 2
        ->  Sort  (cost=8443.80..8443.82 rows=5 width=48) (actual time=66.848..66.853 rows=2 loops=3)
              Sort Key: interest_id
              Sort Method: quicksort  Memory: 1439kB
              Worker 0:  Sort Method: quicksort  Memory: 1370kB
              Worker 1:  Sort Method: quicksort  Memory: 1367kB
              ->  Partial HashAggregate  (cost=8443.68..8443.75 rows=5 width=48) (actual time=51.528..65.614 rows=2 loops=3)
                    Group Key: interest_id
                    Batches: 1  Memory Usage: 2961kB
                    Worker 0:  Batches: 1  Memory Usage: 2961kB
                    Worker 1:  Batches: 1  Memory Usage: 2385kB
                    ->  Parallel Seq Scan on users_interests ui  (cost=0.00..8019.58 rows=84820 width=32) (actual time=0.024..20.705 rows=66667 loops=3)
                          Filter: (interest_id = ANY ('{01f2c804-ea3e-4a36-964d-173b0e7490bf,4e3363f5-673a-4375-b1a4-ff887f63e9fe,c4cb41f8-2cc2-412f-8298-247518a975c3}'::uuid[]))
                          Rows Removed by Filter: 100000
Planning Time: 0.617 ms
Execution Time: 85.449 ms
```

#### 쿼리 1 ~ 3 종합 분석 


아직 인덱스 최적화도 안 했는데 단순히 쿼리만 손댐으로써 이렇게 빠른 속도로 변했습니다.
50M ~ 100M 데이터를 다룰 떄 20분 째 무한로딩 걸리던 쿼리가 무려 125ms의 속도로 변한 것입니다.



### 인덱스 최적화로 추가 성능 개선

흠....
근데 인덱스, 커버링 인덱스 등으로 최적화하는게 과연 맞을까?
서비스 특성상 조회가 많긴 한데 수정, 삽입 작업도 많아서
일단 관련된 기능들을 살펴보자 
1. 기사 
2. 관심사
3. 유저 

- 우선 **기사**는 매시간마다 대량으로 삽입되니까 기사와 관련된 것들을 인덱스로 만들기에는 비용이 많이 들 것 같아서 기사와 관련된 인덱스 ❌ (article, articles_interests ❌)
- 그 다음, **관심사**는 음.... 관심사를 그렇게 자주 수정할 일은 없을 것 같다. 뉴스도 보던 것들만 보는 특성을 가지기에 이거는 해볼만 한 것 같다.
- 그 다음, **유저**는 쿼리에서 user에게 필요한건 id뿐이다. 근데 id는 이미 PRIMARY KEY로 인덱스 등록이 되어있으므로 딱히 쿼리최적화 후 건들 것이 없다. 그래도 users_interests테이블에 user_id관련 필드는 FK이므로 이 부분은 생각해볼만 하다. 인기가 많은 서비스라면 유저가 자주 바뀌겠지만 그렇지 않다고 가정하고 최적화를 위해 해볼만하다 

그럼 이 조건들에 맞아 인덱스를 적용할 수 있는 테이블들은 최종적으로 interests와 users_interests테이블이다.
간단하게 생각해보면 
- users_interests에서는 userId와 interestId부분을 커버링 인덱스로 처리해 볼 수 있다.
- interest도 id, name필드만 필요하므로 이 부분도 가능 ???








| 방법         | 쿼리 수 | JOIN 수 | 메모리 사용량     |
| ---------- | ---- | ------ | ----------- |
| **기존**     | 1개   | 3개     | 높음 (전체 엔티티) |
| **당신 제안**  | N+1개 | 1개     | 중간          |
| **한 방 쿼리** | 1개   | 2개     | 낮음 (필요 컬럼만) |
